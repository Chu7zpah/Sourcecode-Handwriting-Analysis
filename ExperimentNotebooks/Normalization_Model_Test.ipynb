{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Normalization Model Test",
      "provenance": [],
      "authorship_tag": "ABX9TyO7YCzEexpFT30RDIwl5wU1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGyq8Au7y01k",
        "outputId": "03c88f71-1fbb-4c34-8383-872ced106ef1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Chu7zpah/Sourcecode-Handwriting-Analysis/master/CSVResult/Normalized_Final_ABCDEFGH.csv\")\n",
        "print(df)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      inline_NO_brace  inline_YES_brace  ...  YES_binary_YES  Programmer\n",
            "0                 0.0          0.000000  ...        0.710526           A\n",
            "1                 1.0          0.000000  ...        0.193548           A\n",
            "2                 1.0          0.000000  ...        0.187500           A\n",
            "3                 0.0          0.000000  ...        0.571429           A\n",
            "4                 0.0          0.000000  ...        0.000000           A\n",
            "...               ...               ...  ...             ...         ...\n",
            "1244              0.0          0.000000  ...        0.514286           H\n",
            "1245              0.0          0.000000  ...        0.457831           H\n",
            "1246              0.0          0.818182  ...        0.517857           H\n",
            "1247              0.0          0.000000  ...        0.147059           H\n",
            "1248              0.0          0.000000  ...        0.469697           H\n",
            "\n",
            "[1249 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "QqoJxzlG8RII",
        "outputId": "7d149ead-215c-4669-e64f-fc15bd10bfa0"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inline_NO_brace</th>\n",
              "      <th>inline_YES_brace</th>\n",
              "      <th>nextline_brace</th>\n",
              "      <th>double_backslash_NO_Space</th>\n",
              "      <th>double_backslash_YES_Space</th>\n",
              "      <th>single_backslash_asterisk</th>\n",
              "      <th>NO_parenthesis</th>\n",
              "      <th>YES_parenthesis</th>\n",
              "      <th>unary_NO_space</th>\n",
              "      <th>unary_YES_space</th>\n",
              "      <th>NO_binary_NO</th>\n",
              "      <th>NO_binary_YES</th>\n",
              "      <th>YES_binary_NO</th>\n",
              "      <th>YES_binary_YES</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1249.000000</td>\n",
              "      <td>1249.000000</td>\n",
              "      <td>1249.000000</td>\n",
              "      <td>1249.000000</td>\n",
              "      <td>1249.000000</td>\n",
              "      <td>1249.000000</td>\n",
              "      <td>1249.000000</td>\n",
              "      <td>1249.000000</td>\n",
              "      <td>1249.000000</td>\n",
              "      <td>1249.000000</td>\n",
              "      <td>1249.000000</td>\n",
              "      <td>1249.000000</td>\n",
              "      <td>1249.000000</td>\n",
              "      <td>1249.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.011142</td>\n",
              "      <td>0.543292</td>\n",
              "      <td>0.440762</td>\n",
              "      <td>0.056872</td>\n",
              "      <td>0.310871</td>\n",
              "      <td>0.511361</td>\n",
              "      <td>0.077214</td>\n",
              "      <td>0.788279</td>\n",
              "      <td>0.301459</td>\n",
              "      <td>0.102865</td>\n",
              "      <td>0.034724</td>\n",
              "      <td>0.310947</td>\n",
              "      <td>0.146608</td>\n",
              "      <td>0.498914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.073975</td>\n",
              "      <td>0.427054</td>\n",
              "      <td>0.425675</td>\n",
              "      <td>0.118590</td>\n",
              "      <td>0.359838</td>\n",
              "      <td>0.416839</td>\n",
              "      <td>0.240323</td>\n",
              "      <td>0.391759</td>\n",
              "      <td>0.451773</td>\n",
              "      <td>0.292756</td>\n",
              "      <td>0.079817</td>\n",
              "      <td>0.180593</td>\n",
              "      <td>0.147487</td>\n",
              "      <td>0.212652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.085484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.199546</td>\n",
              "      <td>0.041322</td>\n",
              "      <td>0.371542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000771</td>\n",
              "      <td>0.407692</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006452</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.118343</td>\n",
              "      <td>0.516393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.048485</td>\n",
              "      <td>0.676471</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.036145</td>\n",
              "      <td>0.404255</td>\n",
              "      <td>0.203053</td>\n",
              "      <td>0.648178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.870008</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       inline_NO_brace  inline_YES_brace  ...  YES_binary_NO  YES_binary_YES\n",
              "count      1249.000000       1249.000000  ...    1249.000000     1249.000000\n",
              "mean          0.011142          0.543292  ...       0.146608        0.498914\n",
              "std           0.073975          0.427054  ...       0.147487        0.212652\n",
              "min           0.000000          0.000000  ...       0.000000        0.000000\n",
              "25%           0.000000          0.043478  ...       0.041322        0.371542\n",
              "50%           0.000000          0.666667  ...       0.118343        0.516393\n",
              "75%           0.000000          1.000000  ...       0.203053        0.648178\n",
              "max           1.000000          1.000000  ...       1.000000        1.000000\n",
              "\n",
              "[8 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gct0jcPP8eiG"
      },
      "source": [
        "data = df.drop(columns=['Programmer'])\n",
        "label = df['Programmer']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wsd0BhGe8hCu",
        "outputId": "93b8e38d-0ff8-47d5-815b-daf25ac474ce"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn import tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "\n",
        "scaler_dict = {}\n",
        "scaler_dict['std_scaler'] = StandardScaler()\n",
        "scaler_dict['minmax_scaler'] = MinMaxScaler()\n",
        "\n",
        "model_dict = {}\n",
        "model_dict['logistic_regression_ovr'] = LogisticRegression(multi_class='ovr', max_iter=1000)\n",
        "model_dict['logistic_regression_multinomial'] = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
        "model_dict['perceptron'] = Perceptron(max_iter=1000)\n",
        "model_dict['decision_tree'] = tree.DecisionTreeClassifier()\n",
        "model_dict['knn'] = KNeighborsClassifier(n_neighbors=10)\n",
        "model_dict['gaussian_nb'] = GaussianNB()\n",
        "#model_dict['multinomial_nb'] = MultinomialNB()\n",
        "model_dict['bernoulli_nb'] = BernoulliNB()\n",
        "model_dict['random_forest'] = RandomForestClassifier()\n",
        "model_dict['one_vs_one'] = OneVsOneClassifier(SVC())\n",
        "model_dict['one_vs_rest'] = OneVsRestClassifier(SVC())\n",
        "model_dict['mlp'] = MLPClassifier(max_iter=5000)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size= 0.2)\n",
        "\n",
        "for scaler in scaler_dict.keys():\n",
        "  for model in model_dict.keys():\n",
        "    print(scaler)\n",
        "    print(model)\n",
        "    pipe = Pipeline([('scaler', scaler_dict[scaler]), ('model', model_dict[model])])\n",
        "\n",
        "    scores = cross_val_score(pipe, X_train, y_train, cv=5)\n",
        "    print(scores)\n",
        "    print(scores.mean())\n",
        "\n",
        "    pipe.fit(X_train, y_train)\n",
        "\n",
        "    y_preds = pipe.predict(X_test)\n",
        "\n",
        "    print(accuracy_score(y_test, y_preds))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "std_scaler\n",
            "logistic_regression_ovr\n",
            "[0.71       0.75       0.715      0.66       0.66331658]\n",
            "0.6996633165829145\n",
            "0.732\n",
            "std_scaler\n",
            "logistic_regression_multinomial\n",
            "[0.75       0.78       0.685      0.68       0.67839196]\n",
            "0.714678391959799\n",
            "0.736\n",
            "std_scaler\n",
            "perceptron\n",
            "[0.66       0.7        0.59       0.545      0.63819095]\n",
            "0.6266381909547738\n",
            "0.608\n",
            "std_scaler\n",
            "decision_tree\n",
            "[0.755      0.72       0.66       0.69       0.72864322]\n",
            "0.7107286432160804\n",
            "0.78\n",
            "std_scaler\n",
            "knn\n",
            "[0.735      0.77       0.705      0.71       0.71859296]\n",
            "0.7277185929648241\n",
            "0.752\n",
            "std_scaler\n",
            "gaussian_nb\n",
            "[0.6        0.645      0.58       0.635      0.63819095]\n",
            "0.6196381909547739\n",
            "0.644\n",
            "std_scaler\n",
            "bernoulli_nb\n",
            "[0.68       0.74       0.67       0.635      0.67336683]\n",
            "0.6796733668341708\n",
            "0.644\n",
            "std_scaler\n",
            "random_forest\n",
            "[0.83      0.84      0.78      0.785     0.8040201]\n",
            "0.8078040201005026\n",
            "0.84\n",
            "std_scaler\n",
            "one_vs_one\n",
            "[0.8        0.82       0.77       0.73       0.75879397]\n",
            "0.7757587939698493\n",
            "0.768\n",
            "std_scaler\n",
            "one_vs_rest\n",
            "[0.79       0.81       0.76       0.73       0.74371859]\n",
            "0.7667437185929649\n",
            "0.796\n",
            "std_scaler\n",
            "mlp\n",
            "[0.795      0.785      0.705      0.76       0.77889447]\n",
            "0.7647788944723618\n",
            "0.78\n",
            "minmax_scaler\n",
            "logistic_regression_ovr\n",
            "[0.675      0.71       0.715      0.66       0.66834171]\n",
            "0.6856683417085427\n",
            "0.692\n",
            "minmax_scaler\n",
            "logistic_regression_multinomial\n",
            "[0.69       0.735      0.715      0.655      0.63819095]\n",
            "0.6866381909547739\n",
            "0.708\n",
            "minmax_scaler\n",
            "perceptron\n",
            "[0.645      0.67       0.635      0.57       0.51758794]\n",
            "0.6075175879396986\n",
            "0.688\n",
            "minmax_scaler\n",
            "decision_tree\n",
            "[0.76       0.75       0.655      0.705      0.74874372]\n",
            "0.723748743718593\n",
            "0.772\n",
            "minmax_scaler\n",
            "knn\n",
            "[0.73       0.76       0.69       0.69       0.69346734]\n",
            "0.7126934673366834\n",
            "0.732\n",
            "minmax_scaler\n",
            "gaussian_nb\n",
            "[0.6        0.645      0.58       0.64       0.63819095]\n",
            "0.6206381909547739\n",
            "0.644\n",
            "minmax_scaler\n",
            "bernoulli_nb\n",
            "[0.705      0.715      0.69       0.675      0.64824121]\n",
            "0.6866482412060302\n",
            "0.696\n",
            "minmax_scaler\n",
            "random_forest\n",
            "[0.82       0.845      0.785      0.78       0.80904523]\n",
            "0.8078090452261307\n",
            "0.836\n",
            "minmax_scaler\n",
            "one_vs_one\n",
            "[0.755      0.745      0.74       0.69       0.69849246]\n",
            "0.7256984924623116\n",
            "0.736\n",
            "minmax_scaler\n",
            "one_vs_rest\n",
            "[0.725      0.765      0.73       0.71       0.70854271]\n",
            "0.7277085427135678\n",
            "0.748\n",
            "minmax_scaler\n",
            "mlp\n",
            "[0.795      0.87       0.735      0.775      0.77386935]\n",
            "0.7897738693467337\n",
            "0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZj3Jd7b_Hm1",
        "outputId": "288ce05b-c8f5-41aa-b4c0-e82e0587b371"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn import tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "\n",
        "scaler_dict = {}\n",
        "scaler_dict['std_scaler'] = StandardScaler()\n",
        "scaler_dict['minmax_scaler'] = MinMaxScaler()\n",
        "\n",
        "model_dict = {}\n",
        "model_dict['logistic_regression_ovr'] = LogisticRegression(multi_class='ovr', max_iter=1000)\n",
        "model_dict['logistic_regression_multinomial'] = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
        "model_dict['perceptron'] = Perceptron(max_iter=1000)\n",
        "model_dict['decision_tree'] = tree.DecisionTreeClassifier()\n",
        "model_dict['knn'] = KNeighborsClassifier(n_neighbors=10)\n",
        "model_dict['gaussian_nb'] = GaussianNB()\n",
        "#model_dict['multinomial_nb'] = MultinomialNB()\n",
        "model_dict['bernoulli_nb'] = BernoulliNB()\n",
        "model_dict['random_forest'] = RandomForestClassifier()\n",
        "model_dict['one_vs_one'] = OneVsOneClassifier(SVC())\n",
        "model_dict['one_vs_rest'] = OneVsRestClassifier(SVC())\n",
        "model_dict['mlp'] = MLPClassifier(max_iter=5000)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size= 0.2)\n",
        "\n",
        "for model in model_dict.keys():\n",
        "  print(model)\n",
        "  pipe = Pipeline([('model', model_dict[model])])\n",
        "\n",
        "  scores = cross_val_score(pipe, X_train, y_train, cv=5)\n",
        "  print(scores)\n",
        "  print(scores.mean())\n",
        "\n",
        "  pipe.fit(X_train, y_train)\n",
        "\n",
        "  y_preds = pipe.predict(X_test)\n",
        "\n",
        "  print(accuracy_score(y_test, y_preds))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logistic_regression_ovr\n",
            "[0.685      0.645      0.675      0.725      0.66834171]\n",
            "0.6796683417085427\n",
            "0.696\n",
            "logistic_regression_multinomial\n",
            "[0.685      0.655      0.685      0.725      0.68844221]\n",
            "0.6876884422110553\n",
            "0.712\n",
            "perceptron\n",
            "[0.64       0.525      0.58       0.67       0.59296482]\n",
            "0.6015929648241206\n",
            "0.592\n",
            "decision_tree\n",
            "[0.685      0.695      0.735      0.69       0.68341709]\n",
            "0.697683417085427\n",
            "0.744\n",
            "knn\n",
            "[0.715      0.685      0.715      0.71       0.70854271]\n",
            "0.7067085427135678\n",
            "0.716\n",
            "gaussian_nb\n",
            "[0.6        0.595      0.645      0.645      0.59296482]\n",
            "0.6155929648241206\n",
            "0.652\n",
            "bernoulli_nb\n",
            "[0.695      0.715      0.645      0.695      0.68341709]\n",
            "0.686683417085427\n",
            "0.708\n",
            "random_forest\n",
            "[0.765      0.79       0.805      0.775      0.78894472]\n",
            "0.784788944723618\n",
            "0.86\n",
            "one_vs_one\n",
            "[0.725      0.715      0.72       0.73       0.70854271]\n",
            "0.7197085427135679\n",
            "0.728\n",
            "one_vs_rest\n",
            "[0.715      0.71       0.72       0.74       0.69346734]\n",
            "0.7156934673366834\n",
            "0.736\n",
            "mlp\n",
            "[0.745      0.775      0.765      0.745      0.74874372]\n",
            "0.755748743718593\n",
            "0.832\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}